# üöÄ Setup Guide - Qwen Model (Hugging Face)

## ‚úÖ Changes Made

**Switched from Gemini API to Local Qwen Model:**
- ‚ùå No more API keys needed
- ‚ùå No more rate limits  
- ‚úÖ Runs completely locally
- ‚úÖ Free forever
- ‚úÖ Privacy (no data sent to external APIs)

**Model:** Qwen 2.5 - 1.5B Instruct (Alibaba Cloud)
- Size: ~3GB download
- Quality: Good for stock analysis
- Speed: Fast on CPU, faster on GPU

---

## üì¶ Installation Steps

### Step 1: Create Virtual Environment

```powershell
# Make sure you're in the project directory
cd A:\Arel\StockSentinel

# Create virtual environment
python -m venv venv

# Activate virtual environment
venv\Scripts\activate

# Your prompt should now show (venv)

# Install all requirements
pip install -r requirements.txt
```

**What gets installed:**
- `transformers` - Hugging Face library
- `torch` - PyTorch (ML framework)
- `accelerate` - Speed up model loading
- `sentencepiece` - Tokenizer for Qwen
- (plus existing dependencies)

**Note:** First time will download ~3-4GB of files (PyTorch + model)

---

### Step 2: Download the Model (First Run)

The model will download automatically on first run:

```powershell
# Make sure venv is activated (you should see (venv) in prompt)
venv\Scripts\activate

# Test the model download
python main.py
```

**What happens:**
1. Script starts
2. "Loading Qwen 2.5 - 1.5B Instruct model..." appears
3. Downloads model from Hugging Face (~3GB)
4. Loads model into memory
5. Starts analysis

**Download time:** 5-15 minutes (depending on internet speed)

**Storage needed:** ~3GB for model files

---

### Step 3: Verify Installation

After first run completes, you should see:

```
Loading Qwen 2.5 - 1.5B Instruct model...
Using CPU (this will be slower)
Model loaded successfully!

StockSentinel Automated Analysis
==================================================
Analyzing 50 assets...
```

---

## üíª System Requirements

### Minimum Requirements:
- **RAM**: 8GB (model uses ~4GB)
- **Storage**: 5GB free space
- **CPU**: Any modern CPU
- **Time**: ~30-60 minutes for 50 stocks on CPU

### Recommended:
- **RAM**: 16GB+
- **GPU**: NVIDIA GPU with 4GB+ VRAM (10x faster)
- **Storage**: 10GB free
- **Time**: ~5-10 minutes for 50 stocks on GPU

---

## ‚ö° GPU Support (Optional - Much Faster!)

### Check if you have GPU:

```powershell
python -c "import torch; print('GPU Available:', torch.cuda.is_available()); print('GPU Name:', torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'None')"
```

### If you have NVIDIA GPU:

1. **Install CUDA Toolkit** (if not already):
   - Download from: https://developer.nvidia.com/cuda-downloads
   - Install CUDA 11.8 or 12.1

2. **Install PyTorch with CUDA**:
   ```powershell
   pip uninstall torch
   pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
   ```

3. **Run analysis** - It will automatically use GPU!

**Speed improvement:** 5-10x faster than CPU

---

## üîß GitHub Actions Setup

### Update Workflow Settings

The workflow now runs without API keys, but needs more resources:

1. **Go to your repo**: Settings ‚Üí Actions ‚Üí General
2. **Ensure Actions are enabled**
3. **Note:** GitHub Actions runners have:
   - 2 CPU cores
   - 7GB RAM
   - No GPU
   - 6 hour timeout

### Expected Runtime:
- **50 stocks**: ~45-90 minutes on GitHub Actions
- **25 stocks**: ~20-40 minutes (recommended)

### Reduce Watchlist (Recommended):

Edit `main.py` to reduce stocks for faster workflow:

```python
WATCHLIST = [
    # Top 25 stocks only for faster analysis
    "BBCA.JK", "BBRI.JK", "BMRI.JK", "TLKM.JK", "ASII.JK",
    "AAPL", "MSFT", "GOOGL", "AMZN", "NVDA",
    "TSLA", "META", "JPM", "V", "WMT",
    "BTC-USD", "ETH-USD", "BNB-USD", "XRP-USD", "ADA-USD",
    # ... add more as needed
]
```

---

## üìä Local Testing

### Quick Test (3 stocks):

```python
# Edit main.py temporarily
WATCHLIST = ["AAPL", "MSFT", "BTC-USD"]
```

```powershell
python main.py
```

Should complete in ~5-10 minutes on CPU.

---

## üîÑ Push to GitHub

```powershell
# Add all changes
git add .

# Commit
git commit -m "Switch to Qwen local model - no API keys needed"

# Push
git push origin main
```

---

## ‚ñ∂Ô∏è Run Analysis on GitHub

1. **Go to Actions tab**
2. **Click "Manual Stock Analysis Scan"**
3. **Run workflow**
4. **Wait** 45-90 minutes (depends on watchlist size)
5. **Check website** for updated data

---

## üìÅ Model Cache Location

Model files are downloaded to:
- **Windows**: `C:\Users\YourName\.cache\huggingface\hub\`
- **Linux**: `~/.cache/huggingface/hub/`

**Size**: ~3GB

**Reuse**: Once downloaded, model loads instantly next time!

---

## üéØ Performance Comparison

| Hardware | 50 Stocks | 25 Stocks |
|----------|-----------|-----------|
| CPU (4 cores) | 60 min | 30 min |
| CPU (8 cores) | 40 min | 20 min |
| GPU (RTX 3060) | 10 min | 5 min |
| GitHub Actions | 90 min | 40 min |

---

## üêõ Troubleshooting

### "Out of Memory" Error

**Solution 1:** Reduce watchlist size
```python
WATCHLIST = ["AAPL", "MSFT", "GOOGL"]  # Start small
```

**Solution 2:** Use smaller batch size (already optimized)

**Solution 3:** Close other programs

### Model Download Fails

```powershell
# Clear cache and retry
rmdir /s /q C:\Users\YourName\.cache\huggingface
python main.py
```

### Slow Performance

- **Use GPU** if available (10x faster)
- **Reduce watchlist** to 20-25 stocks
- **Close background apps**

### GitHub Actions Timeout (6 hours)

- **Reduce watchlist** to 25-30 stocks maximum
- Workflow will fail if exceeds 6 hours

---

## ‚ú® Benefits of Local Model

### Pros:
- ‚úÖ No API keys needed
- ‚úÖ No rate limits
- ‚úÖ Free forever
- ‚úÖ Complete privacy
- ‚úÖ Works offline (after download)
- ‚úÖ Consistent results

### Cons:
- ‚ùå Slower than cloud APIs (on CPU)
- ‚ùå Requires more RAM
- ‚ùå Larger download (~3GB)
- ‚ùå GitHub Actions slower

---

## üìù Summary

| Aspect | Before (Gemini) | After (Qwen) |
|--------|----------------|--------------|
| **API Key** | Required | Not needed |
| **Rate Limit** | 15 RPM | None |
| **Daily Limit** | 1,500 | Unlimited |
| **Cost** | Free tier | Free forever |
| **Speed (GPU)** | ~4 sec/stock | ~10 sec/stock |
| **Speed (CPU)** | ~4 sec/stock | ~60 sec/stock |
| **Privacy** | Data sent to Google | All local |
| **Setup** | Easy | Moderate |

---

## üöÄ Next Steps

1. **Install dependencies**: `pip install -r requirements.txt`
2. **Test locally**: `python main.py` (with 3 stocks)
3. **Push to GitHub**: `git push origin main`
4. **Run workflow**: GitHub Actions
5. **Check website**: See results!

---

## üìö Additional Resources

- **Qwen Model**: https://huggingface.co/Qwen/Qwen2.5-1.5B-Instruct
- **Hugging Face**: https://huggingface.co/docs
- **PyTorch**: https://pytorch.org/get-started/locally/

---

**Model switched successfully!** üéâ

No more API keys needed - everything runs locally!
